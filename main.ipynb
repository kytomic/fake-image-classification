{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyPOW6prnR7u+fE7BENhlqNt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Msedb4eMuTEe"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/\n","!git clone https://{token}@github.com/kytomic/fake-image-classification.git\n","# Please Enter Your GitHub Token for Cloning the Project\n","token = ''\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"KFXweoSyr1SZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/fake-image-classification/"],"metadata":{"id":"5qKtRkmRtzQU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torchvision\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader"],"metadata":{"id":"LqHhcgoizB5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using GPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"yilLXWjt_VUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preparation\n","## real vs fake images (casia dataset)\n","https://www.kaggle.com/code/shaft49/real-vs-fake-images-casia-dataset\n","\n","Please download the dataset from the link on the discord forum as there is requirements for the file structure."],"metadata":{"id":"4DUyVdHhuLqv"}},{"cell_type":"code","source":["import requests\n","import zipfile\n","from pathlib import Path\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"real_and_fake_face\"\n","\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory\")"],"metadata":{"id":"5MubKf-dGqxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir = image_path / \"training\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"],"metadata":{"id":"l7fdKPh__VWL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","from PIL import Image\n","\n","random.seed(42)\n","image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n","random_image_path = random.choice(image_path_list)\n","image_class = random_image_path.parent.stem\n","img = Image.open(random_image_path)\n","\n","\n","print(f\"Random image path: {random_image_path}\")\n","print(f\"Image class: {image_class}\")\n","print(f\"Image height: {img.height}\")\n","print(f\"Image width: {img.width}\")\n","img"],"metadata":{"id":"RJBxxc8vAgSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_transform = transforms.Compose([\n","    transforms.Resize(size=(256, 256)),\n","    transforms.ToTensor()\n","])"],"metadata":{"id":"tGz7g47GAwh2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n","test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)"],"metadata":{"id":"AGaXHpPOBGYX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names = train_data.classes\n","class_names"],"metadata":{"id":"XDhup7YIJA8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(dataset=train_data,\n","                              batch_size=32,\n","                              num_workers=1,\n","                              shuffle=True)\n","\n","test_dataloader = DataLoader(dataset=test_data,\n","                             batch_size=32,\n","                             num_workers=1,\n","                             shuffle=False)"],"metadata":{"id":"aifQPHu7BpZB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Creation\n"],"metadata":{"id":"Qmn6sp5Xu0aB"}},{"cell_type":"code","source":["class FakeImageModel(nn.Module):\n","  def __init__(self, input_shape, hidden_units, output_shape):\n","    super().__init__()\n","    self.block_1 = nn.Sequential(\n","        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2)\n","    )\n","    self.block_2 = nn.Sequential(\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2)\n","    )\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(in_features=hidden_units*64*64, out_features=output_shape)\n","    )\n","\n","  def xavier_initialization(self, m):\n","    if isinstance(m, nn.Conv2d):\n","      nn.init.xavier_uniform(m.weight)\n","      m.bias.data.fill_(0.01)\n","\n","  def init_weights(self):\n","    self.block_1.apply(self.xavier_initialization)\n","    self.block_2.apply(self.xavier_initialization)\n","\n","\n","  def forward(self, x):\n","    out = self.block_1(x)\n","    # print('Block 1: ', out.shape)\n","\n","    out = self.block_2(out)\n","    # print('Block 2: ', out.shape)\n","\n","    out = self.classifier(out)\n","    # print('Classifier: ', out.shape)\n","\n","    return out\n","\n","torch.manual_seed(42)\n","model = FakeImageModel(input_shape=3, hidden_units=16, output_shape=len(class_names))\n","model.init_weights()\n","model"],"metadata":{"id":"G07MEGLCFYbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class FakeImageModel(nn.Module):\n","  def __init__(self, input_shape, hidden_units, output_shape):\n","    super().__init__()\n","    self.block_1 = nn.Sequential(\n","        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.LeakyReLU(),\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.LeakyReLU(),\n","    )\n","    self.block_2 = nn.Sequential(\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.LeakyReLU(),\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        # nn.ReLU(),\n","    )\n","    self.block_3 = nn.Sequential(\n","        nn.LeakyReLU(),\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=2, stride=2),\n","        nn.LeakyReLU(),\n","    )\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(in_features=hidden_units*32*32, out_features=output_shape)\n","    )\n","\n","  def xavier_initialization(self, m):\n","    if isinstance(m, nn.Conv2d):\n","      nn.init.xavier_uniform(m.weight)\n","      m.bias.data.fill_(0.01)\n","\n","  def init_weights(self):\n","    self.block_1.apply(self.xavier_initialization)\n","    self.block_2.apply(self.xavier_initialization)\n","    self.block_3.apply(self.xavier_initialization)\n","\n","\n","  def forward(self, x):\n","    out = self.block_1(x)\n","    # print('Block 1: ', out.shape)\n","\n","    residual = out\n","    out = self.block_2(out)\n","    out += residual\n","    out = self.block_3(out)\n","\n","    # print('Block 2: ', out.shape)\n","    out = self.block_2(out)\n","    out = self.block_3(out)\n","\n","    # print('Block 2: ', out.shape)\n","    residual = out\n","    out = self.block_2(out)\n","    out += residual\n","    out = self.block_3(out)\n","\n","    # print('Second Block 2: ', out.shape)\n","    out = self.classifier(out)\n","    # print('Classifier: ', out.shape)\n","\n","    return out\n","\n","torch.manual_seed(42)\n","model = FakeImageModel(input_shape=3, hidden_units=10, output_shape=len(class_names))\n","model.init_weights()\n","model"],"metadata":{"id":"qMCMXYMM4ouP"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"AAnNhwyQB5fw"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training and Evaluation"],"metadata":{"id":"0P86tZIJvITi"}},{"cell_type":"code","source":["def accuracy(y_true, y_pred):\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","\n","    return acc"],"metadata":{"id":"C2sgpOpl-JlE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup loss function and optimization algorithm\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.Adam(model.parameters(), 0.1)"],"metadata":{"id":"WurxuVwvvff3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","from tqdm.auto import tqdm\n","torch.manual_seed(42)\n","epochs = 10\n","i = 0\n","\n","for epoch in tqdm(range(epochs)):\n","  print(f'Epoch: {epoch} -----')\n","  train_loss, train_acc = 0, 0\n","\n","  for batch, (X, y) in enumerate(train_dataloader):\n","    model.train()\n","    y_pred = model(X)\n","    loss = loss_fn(y_pred, y)\n","    train_loss += loss.item()\n","    train_acc += accuracy(y_true=y, y_pred=y_pred.argmax(dim=1))\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch % 400 == 0:\n","      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n","\n","  train_loss /= len(train_dataloader)\n","  train_acc /= len(train_dataloader)\n","  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\\n\")\n","\n","  model.eval()\n","  with torch.inference_mode():\n","    test_loss, test_acc = 0.0, 0.0\n","\n","    for X, y in test_dataloader:\n","      test_pred = model(X)\n","      test_loss += loss_fn(test_pred, y).item()\n","      test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1))\n","\n","    test_loss /= len(test_dataloader)\n","    test_acc /= len(test_dataloader)\n","    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"],"metadata":{"id":"ck3AbF8i8F0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","with torch.inference_mode():\n","  test_loss, test_acc = 0.0, 0.0\n","  for X, y in test_dataloader:\n","    test_pred = model(X)\n","    test_loss += loss_fn(test_pred, y)\n","    test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1))\n","\n","  test_loss /= len(test_dataloader)\n","  test_acc /= len(test_dataloader)\n","  print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"],"metadata":{"id":"lPop4AuxU4-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","# Create models directory (if it doesn't already exist)\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents=True, exist_ok=True)\n","\n","# Create model save path\n","MODEL_NAME = \"fake-image-model.pth\"\n","MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n","\n","# Save the model state dict\n","print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n","torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)"],"metadata":{"id":"iGf5i-prxPbl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Note: loading model will error if the shapes here aren't the same as the saved version\n","loaded_model = FakeImageModel(input_shape=3, hidden_units=10, output_shape=len(class_names))\n","\n","# Load in the saved state_dict()\n","loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n","\n","# Send model to GPU\n","loaded_model = loaded_model.to(device)"],"metadata":{"id":"JznJIGrJxnRe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git status"],"metadata":{"id":"T2PFiX_4xxur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"c97yqilaDaU6"},"execution_count":null,"outputs":[]}]}