{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Msedb4eMuTEe"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/"
      ],
      "metadata": {
        "id": "ETDYKEeyuiYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "token = ''"
      ],
      "metadata": {
        "id": "8p6iXMkswY9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://{token}@github.com/kytomic/fake-image-classification.git"
      ],
      "metadata": {
        "id": "SuYQYeAEviJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/fake-image-classification/"
      ],
      "metadata": {
        "id": "qp2DIGhovjv2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "K9eKmWOmxQAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git checkout -b build_cnn"
      ],
      "metadata": {
        "id": "Q3WFrNOpyk6p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "ueY3uEAey8Jg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "import torchvision\n",
        "from torchvision import datasets, transforms\n",
        "from torchvision.transforms import ToTensor\n",
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "LqHhcgoizB5r"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "zHZJIHzB2SWW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pwd"
      ],
      "metadata": {
        "id": "qRiKCeeN4c7b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "id": "yilLXWjt_VUH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import zipfile\n",
        "from pathlib import Path\n",
        "\n",
        "# Setup path to data folder\n",
        "data_path = Path(\"data/\")\n",
        "image_path = data_path / \"real_and_fake_face\"\n",
        "\n",
        "# If the image folder doesn't exist, download it and prepare it...\n",
        "if image_path.is_dir():\n",
        "    print(f\"{image_path} directory exists.\")\n",
        "else:\n",
        "    print(f\"Did not find {image_path} directory, creating one...\")\n",
        "    image_path.mkdir(parents=True, exist_ok=True)"
      ],
      "metadata": {
        "id": "5MubKf-dGqxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = image_path / \"training\"\n",
        "test_dir = image_path / \"test\"\n",
        "\n",
        "train_dir, test_dir"
      ],
      "metadata": {
        "id": "l7fdKPh__VWL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from PIL import Image\n",
        "\n",
        "random.seed(42)\n",
        "image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n",
        "random_image_path = random.choice(image_path_list)\n",
        "image_class = random_image_path.parent.stem\n",
        "img = Image.open(random_image_path)\n",
        "\n",
        "\n",
        "print(f\"Random image path: {random_image_path}\")\n",
        "print(f\"Image class: {image_class}\")\n",
        "print(f\"Image height: {img.height}\")\n",
        "print(f\"Image width: {img.width}\")\n",
        "img"
      ],
      "metadata": {
        "id": "RJBxxc8vAgSe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data_transform = transforms.Compose([\n",
        "    transforms.Resize(size=(64, 64)),\n",
        "    transforms.ToTensor()\n",
        "])"
      ],
      "metadata": {
        "id": "tGz7g47GAwh2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir"
      ],
      "metadata": {
        "id": "VYUhtTRVK1tn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n",
        "test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)"
      ],
      "metadata": {
        "id": "AGaXHpPOBGYX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ls -a data/real_and_fake_face/training"
      ],
      "metadata": {
        "id": "z1Mvyw-WLCCW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class_names = train_data.classes\n",
        "class_names"
      ],
      "metadata": {
        "id": "XDhup7YIJA8x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataloader = DataLoader(dataset=train_data,\n",
        "                              batch_size=1,\n",
        "                              num_workers=1,\n",
        "                              shuffle=True)\n",
        "\n",
        "test_dataloader = DataLoader(dataset=test_data,\n",
        "                             batch_size=1,\n",
        "                             num_workers=1,\n",
        "                             shuffle=False)"
      ],
      "metadata": {
        "id": "aifQPHu7BpZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class FakeImageModel(nn.Module):\n",
        "  def __init__(self, input_shape, hidden_units, output_shape):\n",
        "    super().__init__()\n",
        "    self.block_1 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.block_2 = nn.Sequential(\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n",
        "        nn.ReLU(),\n",
        "        nn.MaxPool2d(kernel_size=2, stride=2)\n",
        "    )\n",
        "    self.classifier = nn.Sequential(\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(in_features=hidden_units*16*16, out_features=output_shape)\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.block_1(x)\n",
        "    # print('Block 1: ', x.shape)\n",
        "    x = self.block_2(x)\n",
        "    # print('Block 2: ', x.shape)\n",
        "    x = self.classifier(x)\n",
        "    # print('Classifier: ', x.shape)\n",
        "    return x\n",
        "\n",
        "torch.manual_seed(42)\n",
        "model = FakeImageModel(input_shape=3, hidden_units=10, output_shape=len(class_names))\n",
        "model"
      ],
      "metadata": {
        "id": "qMCMXYMM4ouP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(y_true, y_pred):\n",
        "    correct = torch.eq(y_true, y_pred).sum().item()\n",
        "    acc = (correct / len(y_pred)) * 100\n",
        "\n",
        "    return acc"
      ],
      "metadata": {
        "id": "C2sgpOpl-JlE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tqdm.auto import tqdm\n",
        "torch.manual_seed(42)\n",
        "epochs = 5\n",
        "\n",
        "loss_fn = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), 0.1)\n",
        "\n",
        "for epoch in tqdm(range(epochs)):\n",
        "  print(f'Epoch: {epoch} -----')\n",
        "  train_loss = 0\n",
        "\n",
        "  for batch, (X, y) in enumerate(train_dataloader):\n",
        "    model.train()\n",
        "    y_pred = model(X)\n",
        "    loss = loss_fn(y_pred, y)\n",
        "    train_loss += loss\n",
        "\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch % 400 == 0:\n",
        "      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n",
        "\n",
        "  train_loss /= len(train_dataloader)\n",
        "  print(f\"Train loss: {train_loss:.5f}\")\n",
        "\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    test_loss, test_acc = 0.0, 0.00\n",
        "\n",
        "    for X, y in test_dataloader:\n",
        "      test_pred = model(X)\n",
        "      test_loss += loss_fn(test_pred, y)\n",
        "      test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "    test_loss /= len(test_dataloader)\n",
        "    test_acc /= len(test_dataloader)\n",
        "    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "ck3AbF8i8F0d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.eval()\n",
        "with torch.inference_mode():\n",
        "  test_loss, test_acc = 0.0, 0.0\n",
        "  for X, y in test_dataloader:\n",
        "    test_pred = model(X)\n",
        "    test_loss += loss_fn(test_pred, y)\n",
        "    test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1))\n",
        "\n",
        "  test_loss /= len(test_dataloader)\n",
        "  test_acc /= len(test_dataloader)\n",
        "  print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"
      ],
      "metadata": {
        "id": "lPop4AuxU4-s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git status"
      ],
      "metadata": {
        "id": "1bDA4eRXYWkC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git add main.ipynb"
      ],
      "metadata": {
        "id": "mn3mEnD0aeEX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git commit -m 'added model and dataset'"
      ],
      "metadata": {
        "id": "uzk2zkHCbRLb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git push --set-upstream origin build_cnn"
      ],
      "metadata": {
        "id": "gUAGLvp5bcmH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git reset --hard HEAD~1"
      ],
      "metadata": {
        "id": "GtF498ApdXh2"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}