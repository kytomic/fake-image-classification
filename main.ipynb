{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"private_outputs":true,"provenance":[],"gpuType":"T4","authorship_tag":"ABX9TyM5tO8cXgyefHqpuLLESmMR"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"Msedb4eMuTEe"},"outputs":[],"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","\n","%cd /content/drive/MyDrive/\n","!git clone https://{token}@github.com/kytomic/fake-image-classification.git\n","# Please Enter Your GitHub Token for Cloning the Project\n","token = ''\n"]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"id":"KFXweoSyr1SZ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["%cd /content/drive/MyDrive/fake-image-classification/"],"metadata":{"id":"5qKtRkmRtzQU"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import torch\n","from torch import nn\n","import torchvision\n","from torchvision import datasets, transforms\n","from torchvision.transforms import ToTensor\n","from torch.utils.data import DataLoader"],"metadata":{"id":"LqHhcgoizB5r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Using GPU\n","device = 'cuda' if torch.cuda.is_available() else 'cpu'\n","device"],"metadata":{"id":"yilLXWjt_VUH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Data Preparation\n","## real vs fake images (casia dataset)\n","https://www.kaggle.com/code/shaft49/real-vs-fake-images-casia-dataset\n","\n","Please download the dataset from the link on the discord forum as there is requirements for the file structure."],"metadata":{"id":"4DUyVdHhuLqv"}},{"cell_type":"code","source":["import requests\n","import zipfile\n","from pathlib import Path\n","\n","# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"real_and_fake_face\"\n","\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory\")"],"metadata":{"id":"5MubKf-dGqxW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dir = image_path / \"training\"\n","test_dir = image_path / \"test\"\n","\n","train_dir, test_dir"],"metadata":{"id":"l7fdKPh__VWL"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["import random\n","from PIL import Image\n","\n","random.seed(35)\n","image_path_list = list(image_path.glob(\"*/*/*.jpg\"))\n","random_image_path = random.choice(image_path_list)\n","image_class = random_image_path.parent.stem\n","img = Image.open(random_image_path)\n","\n","\n","print(f\"Random image path: {random_image_path}\")\n","print(f\"Image class: {image_class}\")\n","print(f\"Image height: {img.height}\")\n","print(f\"Image width: {img.width}\")\n","print(f\"Image name: {str(random_image_path).replace('data/real_and_fake_face/training/fake/', '')}\")\n","img"],"metadata":{"id":"RJBxxc8vAgSe"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["data_transform = transforms.Compose([\n","    transforms.Resize(size=(256, 256)),\n","    transforms.ToTensor()\n","])"],"metadata":{"id":"tGz7g47GAwh2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n","test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)"],"metadata":{"id":"AGaXHpPOBGYX"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["class_names = train_data.classes\n","class_names"],"metadata":{"id":"XDhup7YIJA8x"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_dataloader = DataLoader(dataset=train_data,\n","                              batch_size=32,\n","                              num_workers=1,\n","                              shuffle=True)\n","\n","test_dataloader = DataLoader(dataset=test_data,\n","                             batch_size=32,\n","                             num_workers=1,\n","                             shuffle=False)"],"metadata":{"id":"aifQPHu7BpZB"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Error Level Analysis"],"metadata":{"id":"jeyaPtj34tZk"}},{"cell_type":"code","source":["from PIL import Image\n","import os\n","from pylab import *\n","import re\n","from PIL import Image, ImageChops, ImageEnhance"],"metadata":{"id":"MWrYWvwP4tJj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def get_imlist(path):\n","    return [os.path.join(path,f) for f in os.listdir(path) if f.endswith('.jpg') or f.endswith('.png')]"],"metadata":{"id":"SlWSi2v-4s8l"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_to_ela_image(path, quality):\n","    filename = path\n","    resaved_filename = filename.split('.')[0] + '.resaved.jpg'\n","    ELA_filename = filename.split('.')[0] + '.ela.png'\n","\n","    im = Image.open(filename).convert('RGB')\n","    im.save(resaved_filename, 'JPEG', quality=quality)\n","    resaved_im = Image.open(resaved_filename)\n","\n","    ela_im = ImageChops.difference(im, resaved_im)\n","\n","    extrema = ela_im.getextrema()\n","    max_diff = max([ex[1] for ex in extrema])\n","    if max_diff == 0:\n","        max_diff = 1\n","    scale = 255.0 / max_diff\n","\n","    ela_im = ImageEnhance.Brightness(ela_im).enhance(scale)\n","\n","    return ela_im"],"metadata":{"id":"kyu-Jmbc43kj"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["img"],"metadata":{"id":"3AAS3A9q5dQ-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["convert_to_ela_image('data/real_and_fake_face2/training/fake/easy_91_1000.jpg', 90)"],"metadata":{"id":"lSx_fzIP45vJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_real_path_list = list(image_path.glob(\"training/real/*.jpg\"))\n","train_fake_path_list = list(image_path.glob(\"training/fake/*.jpg\"))\n","test_real_path_list = list(image_path.glob(\"test/real/*.jpg\"))\n","test_fake_path_list = list(image_path.glob(\"test/fake/*.jpg\"))"],"metadata":{"id":"4Wnxc-JP50JW"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def convert_all_to_ela(train_real_path_list, train_fake_path_list, test_real_path_list, test_fake_path_list):\n","  for img_name in train_real_path_list:\n","    img = convert_to_ela_image(str(img_name), 90)\n","    name = str(img_name).replace('data/real_and_fake_face/training/real/', '')\n","    img.save(\"data/preprocessed_images/training/real/\" + name, \"JPEG\")\n","\n","  for img_name in train_fake_path_list:\n","    img = convert_to_ela_image(str(img_name), 90)\n","    name = str(img_name).replace('data/real_and_fake_face/training/fake/', '')\n","    img.save(\"data/preprocessed_images/training/fake/\" + name, \"JPEG\")\n","\n","  for img_name in test_real_path_list:\n","    img = convert_to_ela_image(str(img_name), 90)\n","    name = str(img_name).replace('data/real_and_fake_face/test/real/', '')\n","    img.save(\"data/preprocessed_images/test/real/\" + name, \"JPEG\")\n","\n","  for img_name in test_fake_path_list:\n","    img = convert_to_ela_image(str(img_name), 90)\n","    name = str(img_name).replace('data/real_and_fake_face/test/fake/', '')\n","    img.save(\"data/preprocessed_images/test/fake/\" + name, \"JPEG\")\n","\n","#convert_all_to_ela(train_real_path_list, train_fake_path_list, test_real_path_list, test_fake_path_list)"],"metadata":{"id":"iIuBnRAD-vEd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"preprocessed_images\"\n","\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory\")\n","\n","train_dir = image_path / \"training\"\n","test_dir = image_path / \"test\"\n","\n","data_transform = transforms.Compose([\n","    transforms.Resize(size=(128, 128)),\n","    transforms.ToTensor()\n","])\n","\n","train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n","test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n","\n","class_names = train_data.classes\n","\n","train_dataloader = DataLoader(dataset=train_data,\n","                              batch_size=4,\n","                              num_workers=1,\n","                              shuffle=True)\n","\n","test_dataloader = DataLoader(dataset=test_data,\n","                             batch_size=4,\n","                             num_workers=1,\n","                             shuffle=False)"],"metadata":{"id":"DLjAy1buJEqu"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Creation\n"],"metadata":{"id":"Qmn6sp5Xu0aB"}},{"cell_type":"code","source":["class FakeImageModel(nn.Module):\n","  def __init__(self, input_shape, hidden_units, output_shape):\n","    super().__init__()\n","    self.block_1 = nn.Sequential(\n","        nn.Conv2d(in_channels=input_shape, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2)\n","    )\n","    self.block_2 = nn.Sequential(\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.Conv2d(in_channels=hidden_units, out_channels=hidden_units, kernel_size=3, stride=1, padding=1),\n","        nn.ReLU(),\n","        nn.MaxPool2d(2, 2)\n","    )\n","    self.classifier = nn.Sequential(\n","        nn.Flatten(),\n","        nn.Linear(in_features=hidden_units*32*32, out_features=output_shape)\n","    )\n","\n","  # def xavier_initialization(self, m):\n","  #   if isinstance(m, nn.Conv2d):\n","  #     nn.init.xavier_uniform(m.weight)\n","  #     m.bias.data.fill_(0.01)\n","\n","  # def init_weights(self):\n","  #   self.block_1.apply(self.xavier_initialization)\n","  #   self.block_2.apply(self.xavier_initialization)\n","\n","\n","  def forward(self, x):\n","    out = self.block_1(x)\n","    # print('Block 1: ', out.shape)\n","\n","    out = self.block_2(out)\n","    # print('Block 2: ', out.shape)\n","\n","    out = self.classifier(out)\n","    return out\n","\n","torch.manual_seed(42)\n","model = FakeImageModel(input_shape=3, hidden_units=16, output_shape=len(class_names))\n","# model.init_weights()\n","model"],"metadata":{"id":"G07MEGLCFYbS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def accuracy(y_true, y_pred):\n","    correct = torch.eq(y_true, y_pred).sum().item()\n","    acc = (correct / len(y_pred)) * 100\n","\n","    return acc"],"metadata":{"id":"C2sgpOpl-JlE"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"real_and_fake_face\"\n","\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory\")\n","\n","train_dir = image_path / \"training\"\n","test_dir = image_path / \"test\"\n","\n","data_transform = transforms.Compose([\n","    transforms.Resize(size=(128, 128)),\n","    transforms.ToTensor()\n","])\n","\n","train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n","test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n","\n","class_names = train_data.classes\n","\n","train_dataloader = DataLoader(dataset=train_data,\n","                              batch_size=4,\n","                              num_workers=1,\n","                              shuffle=True)\n","\n","test_dataloader = DataLoader(dataset=test_data,\n","                             batch_size=4,\n","                             num_workers=1,\n","                             shuffle=False)"],"metadata":{"id":"Sci6uJ4fSk9q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup loss function and optimization algorithm\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)"],"metadata":{"id":"YoyW_LTNSq8m"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","from tqdm.auto import tqdm\n","torch.manual_seed(42)\n","epochs = 10\n","train_losses, test_losses = [], []\n","train_accs, test_accs = [], []\n","i = 0\n","\n","for epoch in tqdm(range(epochs)):\n","  print(f'Epoch: {epoch} -----')\n","  train_loss, train_acc = 0, 0\n","\n","  for batch, (X, y) in enumerate(train_dataloader):\n","    model.train()\n","    y_pred = model(X)\n","    loss = loss_fn(y_pred, y)\n","    train_loss += loss.item()\n","    train_acc += accuracy(y_true=y, y_pred=y_pred.argmax(dim=1))\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch % 200 == 0:\n","      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n","\n","  train_loss /= len(train_dataloader)\n","  train_acc /= len(train_dataloader)\n","  train_losses.append(train_loss)\n","  train_accs.append(train_acc)\n","  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\\n\")\n","\n","  model.eval()\n","  with torch.inference_mode():\n","    test_loss, test_acc = 0.0, 0.0\n","\n","    for X, y in test_dataloader:\n","      test_pred = model(X)\n","      test_loss += loss_fn(test_pred, y).item()\n","      test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1))\n","\n","    test_loss /= len(test_dataloader)\n","    test_acc /= len(test_dataloader)\n","    test_losses.append(test_loss)\n","    test_accs.append(test_acc)\n","    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"],"metadata":{"id":"VzbCo1DOStUR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Training accuracies: ', train_accs)\n","print('Test accuracies: ', test_accs)"],"metadata":{"id":"DMAFHpiZSyP4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# DenseNet + ELA"],"metadata":{"id":"MOVdjZXPGJ--"}},{"cell_type":"code","source":["from torchvision import models\n","\n","model = models.densenet121(weights='DenseNet121_Weights.IMAGENET1K_V1')\n","loss_fn = nn.CrossEntropyLoss()\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n"],"metadata":{"id":"yJNm0tNwpTar"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents=True, exist_ok=True)\n","\n","# Create model save path\n","MODEL_NAME = \"dense-fake-image-model.pth\"\n","MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n","\n","# Note: loading model will error if the shapes here aren't the same as the saved version\n","loaded_model = models.densenet121(weights='DenseNet121_Weights.IMAGENET1K_V1')\n","\n","# Load in the saved state_dict()\n","loaded_model.load_state_dict(torch.load(f=MODEL_SAVE_PATH))\n","\n","# Send model to GPU\n","loaded_model = loaded_model.to(device)"],"metadata":{"id":"JznJIGrJxnRe"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Training and Evaluation"],"metadata":{"id":"0P86tZIJvITi"}},{"cell_type":"code","source":["# Setup loss function and optimization algorithm\n","loss_fn = nn.CrossEntropyLoss()\n","# optimizer = torch.optim.Adam(model.parameters(), 0.001)\n","optimizer = torch.optim.SGD(model.parameters(), lr=0.0005, momentum=0.9)"],"metadata":{"id":"WurxuVwvvff3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Setup path to data folder\n","data_path = Path(\"data/\")\n","image_path = data_path / \"preprocessed_images\"\n","\n","if image_path.is_dir():\n","    print(f\"{image_path} directory exists.\")\n","else:\n","    print(f\"Did not find {image_path} directory\")\n","\n","train_dir = image_path / \"training\"\n","test_dir = image_path / \"test\"\n","\n","data_transform = transforms.Compose([\n","    transforms.Resize(size=(128, 128)),\n","    transforms.ToTensor()\n","])\n","\n","train_data = datasets.ImageFolder(root=train_dir, transform=data_transform, target_transform=None)\n","test_data = datasets.ImageFolder(root=test_dir, transform=data_transform)\n","\n","class_names = train_data.classes\n","\n","train_dataloader = DataLoader(dataset=train_data,\n","                              batch_size=4,\n","                              num_workers=1,\n","                              shuffle=True)\n","\n","test_dataloader = DataLoader(dataset=test_data,\n","                             batch_size=4,\n","                             num_workers=1,\n","                             shuffle=False)"],"metadata":{"id":"WeCaJbjBsXA3"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Training Loop\n","from tqdm.auto import tqdm\n","torch.manual_seed(42)\n","epochs = 10\n","train_losses, test_losses = [], []\n","train_accs, test_accs = [], []\n","i = 0\n","\n","for epoch in tqdm(range(epochs)):\n","  print(f'Epoch: {epoch} -----')\n","  train_loss, train_acc = 0, 0\n","\n","  for batch, (X, y) in enumerate(train_dataloader):\n","    model.train()\n","    y_pred = model(X)\n","    loss = loss_fn(y_pred, y)\n","    train_loss += loss.item()\n","    train_acc += accuracy(y_true=y, y_pred=y_pred.argmax(dim=1))\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","\n","    if batch % 200 == 0:\n","      print(f\"Looked at {batch * len(X)}/{len(train_dataloader.dataset)} samples\")\n","\n","  train_loss /= len(train_dataloader)\n","  train_acc /= len(train_dataloader)\n","  train_losses.append(train_loss)\n","  train_accs.append(train_acc)\n","  print(f\"Train loss: {train_loss:.5f} | Train accuracy: {train_acc:.2f}%\\n\")\n","\n","  model.eval()\n","  with torch.inference_mode():\n","    test_loss, test_acc = 0.0, 0.0\n","\n","    for X, y in test_dataloader:\n","      test_pred = model(X)\n","      test_loss += loss_fn(test_pred, y).item()\n","      test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1))\n","\n","    test_loss /= len(test_dataloader)\n","    test_acc /= len(test_dataloader)\n","    test_losses.append(train_loss)\n","    test_accs.append(train_acc)\n","    print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"],"metadata":{"id":"ck3AbF8i8F0d"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.eval()\n","with torch.inference_mode():\n","  test_loss, test_acc = 0.0, 0.0\n","  for X, y in test_dataloader:\n","    test_pred = model(X)\n","    test_loss += loss_fn(test_pred, y)\n","    test_acc += accuracy(y_true=y, y_pred=test_pred.argmax(dim=1))\n","\n","  test_loss /= len(test_dataloader)\n","  test_acc /= len(test_dataloader)\n","  print(f\"Test loss: {test_loss:.5f} | Test accuracy: {test_acc:.2f}%\\n\")"],"metadata":{"id":"lPop4AuxU4-s"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('Training accuracies: ', train_accs)\n","print('Test accuracies: ', test_accs)"],"metadata":{"id":"flFAHqMOIII1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from pathlib import Path\n","\n","# Create models directory (if it doesn't already exist)\n","MODEL_PATH = Path(\"models\")\n","MODEL_PATH.mkdir(parents=True, exist_ok=True)\n","\n","# Create model save path\n","MODEL_NAME = \"dense-fake-image-model.pth\"\n","MODEL_SAVE_PATH = MODEL_PATH / MODEL_NAME\n","\n","# Save the model state dict\n","print(f\"Saving model to: {MODEL_SAVE_PATH}\")\n","torch.save(obj=model.state_dict(), f=MODEL_SAVE_PATH)"],"metadata":{"id":"iGf5i-prxPbl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git status"],"metadata":{"id":"T2PFiX_4xxur"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git add main.ipynb models"],"metadata":{"id":"c97yqilaDaU6"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git commit -m 'CNN and ELA Code adjustment'"],"metadata":{"id":"a8NwPHhXDihd"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git config --global user.email \"kytomic1@gmail.com\""],"metadata":{"id":"_6cqjXtHDwrR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!git push --set-upstream origin build_cnn"],"metadata":{"id":"OfW8UiebD1R5"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gRfszeBvD5kt"},"execution_count":null,"outputs":[]}]}